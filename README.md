# üéóÔ∏è Classifica√ß√£o de Tumores com Machine Learning: Detec√ß√£o de C√¢ncer de Mama

Este projeto consiste na implementa√ß√£o e avalia√ß√£o comparativa de dois modelos de Machine Learning: **Random Forest** e **Support Vector Classifier (SVC)**, para a classifica√ß√£o de tumores (Malignos ou Benignos).

Utilizando um subconjunto do dataset **Breast Cancer Wisconsin**, o estudo foca na sele√ß√£o estrat√©gica de caracter√≠sticas, no impacto do pr√©-processamento dos dados e na an√°lise detalhada das m√©tricas de desempenho.

## üìä Dataset e Features Selecionadas

A sele√ß√£o de caracter√≠sticas foi guiada por uma An√°lise Explorat√≥ria de Dados (EDA). Utilizamos *pairplots* e *heatmaps* de correla√ß√£o para identificar as vari√°veis com maior poder de discrimina√ß√£o entre as classes.

As **4 caracter√≠sticas principais** utilizadas foram:
1. `mean radius`
2. `mean texture`
3. `mean perimeter`
4. `mean area`

## ‚öôÔ∏è Metodologia

O pipeline do projeto seguiu as seguintes etapas:

1.  **Sele√ß√£o de Caracter√≠sticas:** Filtragem das vari√°veis mais correlacionadas com a vari√°vel alvo (`class`).
2.  **Divis√£o dos Dados:** Separa√ß√£o em conjuntos de Treino e Teste.
3.  **Normaliza√ß√£o (StandardScaler):**
    *   Etapa crucial, especialmente para o SVC (que √© baseado em dist√¢ncias).
    *   Garante que todas as features contribuam equitativamente, evitando vi√©s por escala.
4.  **Treinamento:** Ajuste dos modelos `RandomForestClassifier` e `SVC` (Kernel Linear).
5.  **Avalia√ß√£o:** Compara√ß√£o baseada em Acur√°cia e Matriz de Confus√£o.

## üìà Resultados

Ambos os modelos apresentaram desempenho robusto, mas houve uma vantagem para Random Forest.

| Modelo | Acur√°cia | An√°lise |
| :--- | :---: | :--- |
| **Random Forest** | **93.7%** | Apresentou o melhor equil√≠brio, minimizando falsos positivos e negativos. |
| **SVC (Linear)** | 90.9% | Bom poder preditivo, mas ligeiramente inferior ao RF neste cen√°rio espec√≠fico. |

### üß† Insights

A an√°lise das matrizes de confus√£o indicou que o **Random Forest** foi mais eficaz em capturar as nuances dos dados com as features selecionadas. A acur√°cia superior sugere que a estrutura de √°rvores de decis√£o lidou melhor com a separa√ß√£o das classes em compara√ß√£o ao hiperplano linear do SVC neste contexto.

## üöÄ Abra o notebook completo no Colab:

[https://colab.research.google.com/drive/1G58d8Je1_QEaQ7tcmwYzhyR7BiF5EsHH?usp=sharing](https://colab.research.google.com/drive/1G58d8Je1_QEaQ7tcmwYzhyR7BiF5EsHH?usp=sharing)

## üõ†Ô∏è Tecnologias Utilizadas

**Linguagem:** Python

**Manipula√ß√£o de Dados:** Pandas

**Visualiza√ß√£o:** Matplotlib, Seaborn

**Machine Learning:** Scikit-learn

## üìù Conclus√£o

O estudo concluiu que o Random Forest foi o modelo mais eficaz para este problema de classifica√ß√£o com as caracter√≠sticas selecionadas. O projeto ressalta a import√¢ncia da sele√ß√£o de features e da normaliza√ß√£o (StandardScaler) para otimizar modelos baseados em dist√¢ncia e garantir compara√ß√µes justas.
